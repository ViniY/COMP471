{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs sampler demo (uses logs and and unnormalised distribution).\n",
    "\n",
    "We're going to try out Gibbs sampling on the hypercube. The simplest possible case surely?\n",
    "\n",
    "ie. there are $N$ variables, and they're all binary, so there are $2^N$ states, which are the vertices of a hypercube in $N$ dimensions.\n",
    "\n",
    "We'll specify some probability $P(\\mathbf{x})$ for each pattern (= binary string) $\\mathbf{x}$.\n",
    "\n",
    "Then we'll run heaps of Gibbs Sampler updates from some initial state, and count how often the sampler visits each state.\n",
    "\n",
    "If we're right, these counts should come to match our target distribution: bingo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from numpy import array as a\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rng\n",
    "from scipy.special import expit as sigmoid\n",
    "np.set_printoptions(precision = 2, suppress = True)\n",
    "import time\n",
    "rng.seed(int(time.time())) # seed the random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set the patterns up, and give them target probabilities\n",
    "\n",
    "Make up an array with each row being one of the binary patterns. Do 'em all. Give each one some \"target probability\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]  target probability is 1.000\n",
      "[1, 0, 0]  target probability is 2.000\n",
      "[0, 1, 0]  target probability is 4.000\n",
      "[1, 1, 0]  target probability is 8.000\n",
      "[0, 0, 1]  target probability is 16.000\n",
      "[1, 0, 1]  target probability is 32.000\n",
      "[0, 1, 1]  target probability is 64.000\n",
      "[1, 1, 1]  target probability is 128.000\n"
     ]
    }
   ],
   "source": [
    "# make up an array with each row being one of the binary patterns. Do 'em all. Give each one some \"target probability\".\n",
    "\n",
    "N = 3  # dimensionality of the input patterns\n",
    "targProb = {}  # these are going to be dictionaries.\n",
    "testVal = 1.0\n",
    "inpats = []\n",
    "for p in [[0 if (i & (1 << bit) == 0) else 1 for bit in range(N)] for i in range(2**N)]:\n",
    "    inpats.append(p)\n",
    "    targProb[tuple(p)] = testVal\n",
    "    testVal *= 2\n",
    "\n",
    "for p in inpats:\n",
    "    print (\"%s  target probability is %.3f\" % (p, targProb[tuple(p)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here I've made the probabilities really varied - some big, some small - to see whether Gibbs sampler can capture that range successfully.\n",
    "\n",
    "Notice that \"targProb\" is NOT normalised. Gibbs works just fine even if it isn't - it just needs to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 1000 * 2 ** N\n",
    "count = {}\n",
    "for p in inpats:\n",
    "    count[tuple(p)] = 0\n",
    "\n",
    "x = np.zeros(N) # just to start it off\n",
    "for _ in range(ITERATIONS):\n",
    "    index = rng.randint(N)  # choose one dimension, whose value we will reset\n",
    "    x[index] = 1\n",
    "    logProb_with_1 = np.log(targProb[tuple(x)])\n",
    "    x[index] = 0\n",
    "    logProb_with_0 = np.log(targProb[tuple(x)])\n",
    "    \n",
    "    r = sigmoid(logProb_with_1 - logProb_with_0)\n",
    "    if rng.rand() < r:\n",
    "        x[index] = 1 # no need for 'else' since it's zero at this point anyway\n",
    "    count[tuple(x)] += 1\n",
    "\n",
    "empirical = np.array([count[tuple(k)] for k in inpats])\n",
    "theoretical = np.array([targProb[tuple(k)] for k in inpats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare samples made by Gibbs with the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = a(range(2**N))\n",
    "empi = empirical / (np.sum(empirical))\n",
    "theo = theoretical / (np.sum(theoretical))\n",
    "width = 0.35\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(ids, empi, width, color='b', label='empirical')\n",
    "plt.bar(ids+width, theo, width, color='g', label='theoretical')\n",
    "plt.legend()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
